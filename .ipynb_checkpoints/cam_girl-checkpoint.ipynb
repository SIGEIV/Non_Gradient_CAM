{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "import torch\n",
    "import ttach as tta\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageTk, Image\n",
    "from typing import Callable, List, Tuple\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from torchvision import transforms\n",
    "from typing import List, Callable, Optional\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import activations \n",
    "import functions as func\n",
    "import base\n",
    "from cam import CAM\n",
    "#import utils.HuggingfaceToTensorModelWrapper\n",
    "from model_tragets import ClassifierOutputTarget\n",
    "from EigenCAM import EigenCAM\n",
    "from HuggingfaceToTensorModelWrapper import HuggingfaceToTensorModelWrapper\n",
    "from ScoreCAM import ScoreCAM\n",
    "from AblationCAM import AblationCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://c4.wallpaperflare.com/wallpaper/888/896/24/cats-animals-macro-low-resolution-pets-1920x1200-animals-cats-hd-art-wallpaper-preview.jpg',stream=True)\n",
    "#https://www.perc.org/wp-content/uploads/2020/05/wild-horses-central-nevada-1024x704.jpg\n",
    "image = Image.open(io.BytesIO(r.content))\n",
    "size = image.size\n",
    "# define transformt o resize the image with given size\n",
    "transform = T.Resize(size = (250,450))\n",
    "\n",
    "# apply the transform on the input image\n",
    "image = transform(image)\n",
    "transform = transforms.ToTensor()\n",
    "tensor = transform(image).unsqueeze(0)\n",
    "img = np.array(image)\n",
    "tensor = tensor.reshape([ 3, 250, 450])\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54131233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cam_on_image(model: torch.nn.Module,\n",
    "                          target_layer: torch.nn.Module,\n",
    "                          targets_for_cam: List[Callable],\n",
    "                          reshape_transform: Optional[Callable],\n",
    "                          input_tensor: torch.nn.Module=tensor,\n",
    "                          input_image: Image=img,\n",
    "                          method: Callable=CAM):\n",
    "    with method(model=HuggingfaceToTensorModelWrapper(model),\n",
    "                 target_layers=[target_layer],\n",
    "                 reshape_transform=reshape_transform) as cam:\n",
    "\n",
    "        # Replicate the tensor for each of the categories we want to create Grad-CAM for:\n",
    "        repeated_tensor = input_tensor[None, :].repeat(len(targets_for_cam), 1, 1, 1)\n",
    "\n",
    "        batch_results = cam(input_tensor=repeated_tensor,\n",
    "                            targets=targets_for_cam)\n",
    "        results = []\n",
    "        for grayscale_cam in batch_results:\n",
    "            visualization = func.show_cam_on_image(np.float32(input_image)/255,\n",
    "                                              grayscale_cam,\n",
    "                                              use_rgb=True)\n",
    "            # Make it weight less in the notebook:\n",
    "            visualization = cv2.resize(visualization,\n",
    "                                       (visualization.shape[1]//2, visualization.shape[0]//2))\n",
    "            results.append(visualization)\n",
    "    return np.hstack(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f873ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MobileViTForImageClassification\n",
    "model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-small\")\n",
    "#target_layer = model.mobilevit.conv_1x1_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_for_cam = [ClassifierOutputTarget(func.category_name_to_index(model, \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\")),\n",
    "                       ClassifierOutputTarget(func.category_name_to_index(model, \"coucal\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacfdcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Now with EigenCAM :')\n",
    "cam_image = run_cam_on_image(model=model,\n",
    "                      target_layer=model.mobilevit.encoder.layer[-2],\n",
    "                      targets_for_cam=targets_for_cam,\n",
    "                      reshape_transform=None,\n",
    "                      method=EigenCAM)\n",
    "display(Image.fromarray(cam_image))\n",
    "func.print_top_categories(model, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Now with ScoreCAM :')\n",
    "display(Image.fromarray(run_cam_on_image(model=model,\n",
    "                      target_layer=model.mobilevit.encoder.layer[-2],\n",
    "                      targets_for_cam=targets_for_cam,\n",
    "                      reshape_transform=None,\n",
    "                      method=ScoreCAM)))\n",
    "func.print_top_categories(model, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Now with AblationCAM :')\n",
    "display(Image.fromarray(run_cam_on_image(model=model,\n",
    "                      target_layer=model.mobilevit.encoder.layer[-2],\n",
    "                      targets_for_cam=targets_for_cam,\n",
    "                      reshape_transform=None,\n",
    "                      method=AblationCAM)))\n",
    "func.print_top_categories(model, tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
